{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1(+6). Проверить, сбалансирован ли датасет (может быть, наблюдений одного класса слишком много?). Какие результаты покажет dummy classifier, который будет всем новым наблюдениям присваивать класс ham? Насколько плохо такое решение для задачи определения спама?\n",
    "\n",
    "Грубое решение - включить в training set только необходимое число наблюдений (примерно поровну spam и ham). \n",
    "Нормализовать тексты и обучить байесовскую модель (bag of words). Проверить, как влияют на результат:\n",
    "\n",
    "1) разная токенизация: в одном случае знаки препинания удалять, в другом — считать их токенами;\n",
    "\n",
    "2) лемматизация (отсутствие лемматизации, стемминг, лемматизация; инструменты можно использовать любые, например, nltk.stem);\n",
    "\n",
    "3) удаление стоп-слов, а также пороги минимальной и максимальной document frequency;\n",
    "\n",
    "4) векторизация документов (CountVectorizer vs. TfIdfVectorizer);\n",
    "\n",
    "5) что-нибудь ещё?\n",
    "\n",
    "При оценке классификатора обратите внимание на TP и FP.\n",
    "\n",
    "Extra: ограничив количество наблюдений ham в обучающей выборке, мы игнорируем довольно много данных. 1) В цикле: случайно выбрать нужное число писем ham и сконструировать сбалансированную выборку, построить классификатор, оценить и записать результат; в итоге результаты усреднить. 2) поможет ли параметр class prior probability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'smsspamcollection/SMSSpamCollection'\n",
    "\n",
    "messages = pd.read_csv(path, sep='\\t',\n",
    "                           names=[\"label\", \"message\"])\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузили, посмотрели. Смотрим на классы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                        message\n",
      "label                                                          \n",
      "ham   count                                                4825\n",
      "      unique                                               4516\n",
      "      top                                Sorry, I'll call later\n",
      "      freq                                                   30\n",
      "spam  count                                                 747\n",
      "      unique                                                653\n",
      "      top     Please call our customer service representativ...\n",
      "      freq                                                    4\n"
     ]
    }
   ],
   "source": [
    "print(messages.groupby('label').describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выборка очевидно несбалансирована по классам (~6:1). Соответственно, dummy-classifier, всегда присваивающий ярлык \"ham\", будет иметь accuracy ~86%, а confusion matrix будет выглядеть вот так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf_ham</th>\n",
       "      <th>clf_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      clf_ham  clf_spam\n",
       "ham      4825         0\n",
       "spam      747         0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'clf_ham': pd.Series([4825, 747], index=['ham', 'spam']),\n",
    "    'clf_spam': pd.Series([0, 0], index=['ham', 'spam'])}\n",
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для задачи определения спама такой классификатор абсолютно бесполезен просто по определению: это классификатор, который никогда не определяет спам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соотношение 6:1 - вот и отлично, разделим ham на шесть непересекающихся выборок, обучим классификатор с каждым"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                       4825\n",
       "unique                      4516\n",
       "top       Sorry, I'll call later\n",
       "freq                          30\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# возьмём все сообщения ham (и все сообщения spam заодно)\n",
    "ham = messages.loc[messages['label']=='ham']['message']\n",
    "spam = messages.loc[messages['label']=='spam']['message']\n",
    "ham.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>793</td>\n",
       "      <td>783</td>\n",
       "      <td>782</td>\n",
       "      <td>798</td>\n",
       "      <td>790</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>I cant pick the phone right now. Pls send a me...</td>\n",
       "      <td>I am in hospital da. . I will return home in e...</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0                       1  \\\n",
       "count                      804                     804   \n",
       "unique                     793                     783   \n",
       "top     Sorry, I'll call later  Sorry, I'll call later   \n",
       "freq                         5                       7   \n",
       "\n",
       "                                                        2  \\\n",
       "count                                                 804   \n",
       "unique                                                782   \n",
       "top     I cant pick the phone right now. Pls send a me...   \n",
       "freq                                                    5   \n",
       "\n",
       "                                                        3  \\\n",
       "count                                                 804   \n",
       "unique                                                798   \n",
       "top     I am in hospital da. . I will return home in e...   \n",
       "freq                                                    2   \n",
       "\n",
       "                             4                       5  \n",
       "count                      804                     804  \n",
       "unique                     790                     785  \n",
       "top     Sorry, I'll call later  Sorry, I'll call later  \n",
       "freq                         4                       9  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# поделим на шесть равных выборок и запишем в датафрейм (игнорируем в итоге не больше пяти наблюдений)\n",
    "ham_samples = pd.DataFrame(np.array([ham[i*6:i*6+6] for i in range(len(ham)//6)]))\n",
    "\n",
    "ham_samples.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут главное не пугаться одинаковых сообщений в разных выборках, это же топчик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    [free, entry, in, 2, a, wkly, comp, to, win, f...\n",
      "Name: message, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[go, until, jurong, point, ,, crazy.., availab...</td>\n",
       "      <td>[ok, lar, ..., joking, wif, u, oni, ...]</td>\n",
       "      <td>[u, dun, say, so, early, hor, ..., u, c, alrea...</td>\n",
       "      <td>[nah, i, do, n't, think, he, goes, to, usf, ,,...</td>\n",
       "      <td>[even, my, brother, is, not, like, to, speak, ...</td>\n",
       "      <td>[as, per, your, request, 'melle, melle, (, oru...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  [go, until, jurong, point, ,, crazy.., availab...   \n",
       "\n",
       "                                          1  \\\n",
       "0  [ok, lar, ..., joking, wif, u, oni, ...]   \n",
       "\n",
       "                                                   2  \\\n",
       "0  [u, dun, say, so, early, hor, ..., u, c, alrea...   \n",
       "\n",
       "                                                   3  \\\n",
       "0  [nah, i, do, n't, think, he, goes, to, usf, ,,...   \n",
       "\n",
       "                                                   4  \\\n",
       "0  [even, my, brother, is, not, like, to, speak, ...   \n",
       "\n",
       "                                                   5  \n",
       "0  [as, per, your, request, 'melle, melle, (, oru...  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dummy tokenizer\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    return word_tokenize(text)\n",
    "\n",
    "\n",
    "ham_split = [ham_samples[i].map(tokenize) for i in range(6)]\n",
    "\n",
    "ham_tok = pd.DataFrame(np.array(ham_split).T)\n",
    "spam_tok = spam.map(tokenize)\n",
    "\n",
    "print(spam_tok.head(1))\n",
    "ham_tok.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-90-3a143b86198b>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-90-3a143b86198b>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    def get_rid(arr):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# теперь токенизация без знаков препинания\n",
    "import string\n",
    "def get_rid(arr):\n",
    "    res = [x for x in arr if x not in string.punctuation]\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "messages['length'] = messages['message'].map(lambda text: len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(messages.head())\n",
    "\n",
    "# tokens = [word_tokenize(msg) for msg in messages]\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    return word_tokenize(text)\n",
    "\n",
    "# messages.message.head().apply(tokenize)\n",
    "# messages.message = messages.message.apply(tokenize)\n",
    "\n",
    "# print(messages.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bow = CountVectorizer()\n",
    "bow.fit_transform(messages['message'])\n",
    "# print(bow.vocabulary_)\n",
    "\n",
    "# m = messages['message'][3]\n",
    "# print([m])\n",
    "# bowed_m = bow.transform([m])\n",
    "# print(bowed_m.shape)\n",
    "# print(bow.get_feature_names()[1054])\n",
    "\n",
    "bowed_messages = bow.transform(messages['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "naive_model = MultinomialNB()\n",
    "naive_model.fit(bowed_messages, messages['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# naive_model.predict()\n",
    "\n",
    "# msg_train, msg_test, label_train, label_test = train_test_split(messages['message'], messages['label'], test_size=0.2)\n",
    "# print(len(msg_train), len(msg_test))\n",
    "cv_results = cross_val_score(naive_model, bowed_messages, messages['label'], cv=10, scoring='accuracy')\n",
    "print(cv_results.mean(), cv_results.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pipeline = Pipeline([\n",
    "#     ('bow', CountVectorizer(analyzer=tokenize)),\n",
    "#     ('classifier', MultinomialNB()),\n",
    "# ])\n",
    "#\n",
    "# cv_results = cross_val_score(pipeline,\n",
    "#                              msg_train,\n",
    "#                              label_train,\n",
    "#                              cv=10,\n",
    "#                              scoring='accuracy',\n",
    "#                              )\n",
    "# print(cv_results.mean(), cv_results.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "2(+2). Сравнить результаты байесовского классификатора, решающего дерева и RandomForest. Помимо стандартных метрик оценки качества модели, необходимо построить learning curve, ROC-curve, classification report и интерпретировать эти результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3(+2). А что, если в качестве предикторов брать не количество вхождений слов, а конструировать специальные признаки? Прежде всего, необходимо разделить таблицу на training set и test set в соотношении 80:20, test set не открывать до этапа оценки модели. С помощью pandas проверить, отличаются ли перечисленные ниже параметры (иможно придумать другие) для разных классов (spam/ham), и собрать матрицу признаков для обучения. Примеры признаков: длина сообщения, количество букв в ВЕРХНЕМ РЕГИСТРЕ, восклицательных знаков, цифр, запятых, каких-то конкретных слов (для этого можно построить частотный словарь по сообщениям каждого класса). Прокомментировать свой выбор. Векторизовать документы и построить классификатор. Оценить модель на проверочной выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
