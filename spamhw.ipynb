{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) удаление стоп-слов, а также пороги минимальной и максимальной document frequency;\n",
    "\n",
    "4) векторизация документов (CountVectorizer vs. TfIdfVectorizer);\n",
    "\n",
    "5) что-нибудь ещё?\n",
    "\n",
    "При оценке классификатора обратите внимание на TP и FP.\n",
    "\n",
    "построить классификатор, оценить и записать результат; в итоге результаты усреднить. 2) поможет ли параметр class prior probability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'smsspamcollection/SMSSpamCollection'\n",
    "\n",
    "messages = pd.read_csv(path, sep='\\t',\n",
    "                           names=[\"label\", \"message\"])\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузили, посмотрели. Смотрим на классы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                        message\n",
      "label                                                          \n",
      "ham   count                                                4825\n",
      "      unique                                               4516\n",
      "      top                                Sorry, I'll call later\n",
      "      freq                                                   30\n",
      "spam  count                                                 747\n",
      "      unique                                                653\n",
      "      top     Please call our customer service representativ...\n",
      "      freq                                                    4\n"
     ]
    }
   ],
   "source": [
    "print(messages.groupby('label').describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выборка очевидно несбалансирована по классам (~6:1). Соответственно, dummy-classifier, всегда присваивающий ярлык \"ham\", будет иметь accuracy ~86%, а confusion matrix будет выглядеть вот так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf_ham</th>\n",
       "      <th>clf_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      clf_ham  clf_spam\n",
       "ham      4825         0\n",
       "spam      747         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'clf_ham': pd.Series([4825, 747], index=['ham', 'spam']),\n",
    "    'clf_spam': pd.Series([0, 0], index=['ham', 'spam'])}\n",
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для задачи определения спама такой классификатор абсолютно бесполезен просто по определению: это классификатор, который никогда не определяет спам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соотношение 6:1 - вот и отлично, разделим ham на шесть непересекающихся выборок, обучим классификатор с каждым"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# токенизируем, лемматизируем, стеммим, всё вот это запихиваем в один датафрейм\n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    return word_tokenize(text)\n",
    "\n",
    "\n",
    "msg_tok = messages['message'].map(tokenize)\n",
    "\n",
    "\n",
    "def get_rid(arr):\n",
    "    res = [x for x in arr if x not in string.punctuation]\n",
    "    return res\n",
    "\n",
    "\n",
    "msg_tok_no_punct = msg_tok.map(get_rid)\n",
    "\n",
    "\n",
    "lm = WordNetLemmatizer()\n",
    "st = LancasterStemmer()\n",
    "\n",
    "\n",
    "def lemmatize(arr):\n",
    "    return list(map(lm.lemmatize, arr))\n",
    "\n",
    "\n",
    "def stem(arr):\n",
    "    return list(map(st.stem, arr))\n",
    "\n",
    "msg_df = pd.DataFrame({'tokenized_punct': msg_tok, 'tokenized_no_punct': msg_tok_no_punct, \n",
    "                    'punctlem': msg_tok.map(lemmatize), 'punctstem': ham_tok.map(stem), \n",
    "                    'nopunctlem': msg_tok_no_punct.map(lemmatize), 'nopunctstem': msg_tok_no_punct.map(stem), \n",
    "                    'label': messages['label']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>nopunctlem</th>\n",
       "      <th>nopunctstem</th>\n",
       "      <th>punctlem</th>\n",
       "      <th>punctstem</th>\n",
       "      <th>tokenized_no_punct</th>\n",
       "      <th>tokenized_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[go, until, jurong, point, crazy.., available,...</td>\n",
       "      <td>[go, until, jurong, point, crazy.., avail, on,...</td>\n",
       "      <td>[go, until, jurong, point, ,, crazy.., availab...</td>\n",
       "      <td>[go, until, jurong, point, ,, crazy.., avail, ...</td>\n",
       "      <td>[go, until, jurong, point, crazy.., available,...</td>\n",
       "      <td>[go, until, jurong, point, ,, crazy.., availab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar, ..., joking, wif, u, oni, ...]</td>\n",
       "      <td>[ok, lar, ..., jok, wif, u, on, ...]</td>\n",
       "      <td>[ok, lar, ..., joking, wif, u, oni, ...]</td>\n",
       "      <td>[ok, lar, ..., jok, wif, u, on, ...]</td>\n",
       "      <td>[ok, lar, ..., joking, wif, u, oni, ...]</td>\n",
       "      <td>[ok, lar, ..., joking, wif, u, oni, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "      <td>[fre, entry, in, 2, a, wkly, comp, to, win, fa...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[u, dun, say, so, early, hor, ..., u, c, alrea...</td>\n",
       "      <td>[u, dun, say, so, ear, hor, ..., u, c, already...</td>\n",
       "      <td>[u, dun, say, so, early, hor, ..., u, c, alrea...</td>\n",
       "      <td>[u, dun, say, so, ear, hor, ..., u, c, already...</td>\n",
       "      <td>[u, dun, say, so, early, hor, ..., u, c, alrea...</td>\n",
       "      <td>[u, dun, say, so, early, hor, ..., u, c, alrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, i, do, n't, think, he, go, to, usf, he, ...</td>\n",
       "      <td>[nah, i, do, n't, think, he, goe, to, usf, he,...</td>\n",
       "      <td>[nah, i, do, n't, think, he, go, to, usf, ,, h...</td>\n",
       "      <td>[nah, i, do, n't, think, he, goe, to, usf, ,, ...</td>\n",
       "      <td>[nah, i, do, n't, think, he, goes, to, usf, he...</td>\n",
       "      <td>[nah, i, do, n't, think, he, goes, to, usf, ,,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                         nopunctlem  \\\n",
       "0   ham  [go, until, jurong, point, crazy.., available,...   \n",
       "1   ham           [ok, lar, ..., joking, wif, u, oni, ...]   \n",
       "2  spam  [free, entry, in, 2, a, wkly, comp, to, win, f...   \n",
       "3   ham  [u, dun, say, so, early, hor, ..., u, c, alrea...   \n",
       "4   ham  [nah, i, do, n't, think, he, go, to, usf, he, ...   \n",
       "\n",
       "                                         nopunctstem  \\\n",
       "0  [go, until, jurong, point, crazy.., avail, on,...   \n",
       "1               [ok, lar, ..., jok, wif, u, on, ...]   \n",
       "2  [fre, entry, in, 2, a, wkly, comp, to, win, fa...   \n",
       "3  [u, dun, say, so, ear, hor, ..., u, c, already...   \n",
       "4  [nah, i, do, n't, think, he, goe, to, usf, he,...   \n",
       "\n",
       "                                            punctlem  \\\n",
       "0  [go, until, jurong, point, ,, crazy.., availab...   \n",
       "1           [ok, lar, ..., joking, wif, u, oni, ...]   \n",
       "2  [free, entry, in, 2, a, wkly, comp, to, win, f...   \n",
       "3  [u, dun, say, so, early, hor, ..., u, c, alrea...   \n",
       "4  [nah, i, do, n't, think, he, go, to, usf, ,, h...   \n",
       "\n",
       "                                           punctstem  \\\n",
       "0  [go, until, jurong, point, ,, crazy.., avail, ...   \n",
       "1               [ok, lar, ..., jok, wif, u, on, ...]   \n",
       "2                                                NaN   \n",
       "3  [u, dun, say, so, ear, hor, ..., u, c, already...   \n",
       "4  [nah, i, do, n't, think, he, goe, to, usf, ,, ...   \n",
       "\n",
       "                                  tokenized_no_punct  \\\n",
       "0  [go, until, jurong, point, crazy.., available,...   \n",
       "1           [ok, lar, ..., joking, wif, u, oni, ...]   \n",
       "2  [free, entry, in, 2, a, wkly, comp, to, win, f...   \n",
       "3  [u, dun, say, so, early, hor, ..., u, c, alrea...   \n",
       "4  [nah, i, do, n't, think, he, goes, to, usf, he...   \n",
       "\n",
       "                                     tokenized_punct  \n",
       "0  [go, until, jurong, point, ,, crazy.., availab...  \n",
       "1           [ok, lar, ..., joking, wif, u, oni, ...]  \n",
       "2  [free, entry, in, 2, a, wkly, comp, to, win, f...  \n",
       "3  [u, dun, say, so, early, hor, ..., u, c, alrea...  \n",
       "4  [nah, i, do, n't, think, he, goes, to, usf, ,,...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# строим пайплайны\n",
    "CV_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                   ('tfidf', TfidfTransformer()), \n",
    "                   ('clf', MultinomialNB()),])\n",
    "TI_clf = Pipeline([('vect', TfidfVectorizer()),\n",
    "                   ('tfidf', TfidfTransformer()), \n",
    "                   ('clf', MultinomialNB()),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# и настраиваем gridsearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vect__stop_words': [None, 'english'],\n",
    "              'vect__min_df': [1, 3],\n",
    "              'vect__max_df': [1.0, 0.8],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# теперь будем это всё делить.\n",
    "# и запускать.\n",
    "\n",
    "ham = msg_df.loc[msg_df['label']=='ham']\n",
    "spam = msg_df.loc[msg_df['label']=='spam']\n",
    "\n",
    "\n",
    "gs_stats = []\n",
    "\n",
    "# 0 колонка - это label, его не перебираем\n",
    "for column in msg_df.columns[1:]:\n",
    "    for i in range(len(ham)//6):\n",
    "        hham = ham[i*6:i*6+6]\n",
    "        # очень плохо, что они не перемешаны, ноо\n",
    "        sample = pd.concat([spam, hham])\n",
    "        X = sample[column]\n",
    "        y = sample['label']\n",
    "        gs_cv = GridSearchCV(CV_clf, parameters)\n",
    "        gs_ti = GridSearchCV(TI_clf, parameters)\n",
    "        gs_cv.fit(X, y)\n",
    "        gs_ti.fit(X, y)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'label'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_df.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>793</td>\n",
       "      <td>783</td>\n",
       "      <td>782</td>\n",
       "      <td>798</td>\n",
       "      <td>790</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>I cant pick the phone right now. Pls send a me...</td>\n",
       "      <td>I am in hospital da. . I will return home in e...</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0                       1  \\\n",
       "count                      804                     804   \n",
       "unique                     793                     783   \n",
       "top     Sorry, I'll call later  Sorry, I'll call later   \n",
       "freq                         5                       7   \n",
       "\n",
       "                                                        2  \\\n",
       "count                                                 804   \n",
       "unique                                                782   \n",
       "top     I cant pick the phone right now. Pls send a me...   \n",
       "freq                                                    5   \n",
       "\n",
       "                                                        3  \\\n",
       "count                                                 804   \n",
       "unique                                                798   \n",
       "top     I am in hospital da. . I will return home in e...   \n",
       "freq                                                    2   \n",
       "\n",
       "                             4                       5  \n",
       "count                      804                     804  \n",
       "unique                     790                     785  \n",
       "top     Sorry, I'll call later  Sorry, I'll call later  \n",
       "freq                         4                       9  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# поделим на шесть равных выборок и запишем в датафрейм (игнорируем в итоге не больше пяти наблюдений)\n",
    "ham_samples = pd.DataFrame(np.array([ham[i*6:i*6+6] for i in range(len(ham)//6)]))\n",
    "\n",
    "ham_samples.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "2(+2). Сравнить результаты байесовского классификатора, решающего дерева и RandomForest. Помимо стандартных метрик оценки качества модели, необходимо построить learning curve, ROC-curve, classification report и интерпретировать эти результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3(+2). А что, если в качестве предикторов брать не количество вхождений слов, а конструировать специальные признаки? Прежде всего, необходимо разделить таблицу на training set и test set в соотношении 80:20, test set не открывать до этапа оценки модели. С помощью pandas проверить, отличаются ли перечисленные ниже параметры (иможно придумать другие) для разных классов (spam/ham), и собрать матрицу признаков для обучения. Примеры признаков: длина сообщения, количество букв в ВЕРХНЕМ РЕГИСТРЕ, восклицательных знаков, цифр, запятых, каких-то конкретных слов (для этого можно построить частотный словарь по сообщениям каждого класса). Прокомментировать свой выбор. Векторизовать документы и построить классификатор. Оценить модель на проверочной выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "messages['length'] = messages['message'].map(lambda text: len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(messages.head())\n",
    "\n",
    "# tokens = [word_tokenize(msg) for msg in messages]\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    return word_tokenize(text)\n",
    "\n",
    "# messages.message.head().apply(tokenize)\n",
    "# messages.message = messages.message.apply(tokenize)\n",
    "\n",
    "# print(messages.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bow = CountVectorizer()\n",
    "bow.fit_transform(messages['message'])\n",
    "# print(bow.vocabulary_)\n",
    "\n",
    "# m = messages['message'][3]\n",
    "# print([m])\n",
    "# bowed_m = bow.transform([m])\n",
    "# print(bowed_m.shape)\n",
    "# print(bow.get_feature_names()[1054])\n",
    "\n",
    "bowed_messages = bow.transform(messages['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "naive_model = MultinomialNB()\n",
    "naive_model.fit(bowed_messages, messages['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# naive_model.predict()\n",
    "\n",
    "# msg_train, msg_test, label_train, label_test = train_test_split(messages['message'], messages['label'], test_size=0.2)\n",
    "# print(len(msg_train), len(msg_test))\n",
    "cv_results = cross_val_score(naive_model, bowed_messages, messages['label'], cv=10, scoring='accuracy')\n",
    "print(cv_results.mean(), cv_results.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pipeline = Pipeline([\n",
    "#     ('bow', CountVectorizer(analyzer=tokenize)),\n",
    "#     ('classifier', MultinomialNB()),\n",
    "# ])\n",
    "#\n",
    "# cv_results = cross_val_score(pipeline,\n",
    "#                              msg_train,\n",
    "#                              label_train,\n",
    "#                              cv=10,\n",
    "#                              scoring='accuracy',\n",
    "#                              )\n",
    "# print(cv_results.mean(), cv_results.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
